{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Predicting Customer Satisfaction**\n",
    "## *Given survey data from an Airline, can we predict the satisfaction of a customer? *\n",
    "\n",
    "\n",
    "Welcome! This kernels aim is to showcase a few of the basics of data science (data cleaning, encoding, feature engineering, and model training), all while attempting to solve a problem that is common among businesses: *Customer Satisfaction*. \n",
    "\n",
    "We will be treating this as a binary classification problem, where we will attemp to create a model that predicts whether a customer was **Satisfied** or **Unsatisfied** with the experience and/or service which an airline provided.\n",
    "\n",
    "**If you find this kernel helpful, please UPVOTE**\n",
    "\n",
    "V10 - Fixed bug where test data was being set to train data\n",
    "\n",
    "V9 - Initial Public Kernel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notes about the Dataset\n",
    "This dataset has already been split into train and test csv files. 80% of the total dataset is in train.csv and 20% is in test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-input": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import lightgbm as lgb\n",
    "import xgboost as xgb\n",
    "import catboost as cb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, accuracy_score, plot_confusion_matrix, classification_report\n",
    "from scipy import stats\n",
    "\n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "warnings.filterwarnings(action='ignore', category=DataConversionWarning)\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "#![image.png](attachment:image.png)        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_kg_hide-input": false,
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "directory = \"/kaggle/input/airline-passenger-satisfaction/\"\n",
    "feature_tables = ['train.csv', 'test.csv']\n",
    "\n",
    "df_train = directory + feature_tables[0]\n",
    "df_test = directory + feature_tables[1]\n",
    "\n",
    "# Create dataframes\n",
    "print(f'Reading csv from {df_train}...')\n",
    "train = pd.read_csv(df_train)\n",
    "print('...Complete')\n",
    "\n",
    "print(f'Reading csv from {df_train}...')\n",
    "test = pd.read_csv(df_test)\n",
    "print('...Complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean and Transform Dataset\n",
    "Based on the training data above, there are several things we need to do in order to prepare the data for use in a model. There are several catagorical variables that need to be encoded, including our target variable 'Satisfaction'. There are also a couple of columns that are unnecessary, such as 'Unnamed:0' and 'id'. We can drop these. The functions below will be used to perform the dataset preparation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "def transform_gender(x):\n",
    "    if x == 'Female':\n",
    "        return 1\n",
    "    elif x == 'Male':\n",
    "        return 0\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "def transform_customer_type(x):\n",
    "    if x == 'Loyal Customer':\n",
    "        return 1\n",
    "    elif x == 'disloyal Customer':\n",
    "        return 0\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "def transform_travel_type(x):\n",
    "    if x == 'Business travel':\n",
    "        return 1\n",
    "    elif x == 'Personal Travel':\n",
    "        return 0\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "def transform_class(x):\n",
    "    if x == 'Business':\n",
    "        return 2\n",
    "    elif x == 'Eco Plus':\n",
    "        return 1\n",
    "    elif x == 'Eco':\n",
    "        return 0    \n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "def transform_satisfaction(x):\n",
    "    if x == 'satisfied':\n",
    "        return 1\n",
    "    elif x == 'neutral or dissatisfied':\n",
    "        return 0\n",
    "    else:\n",
    "        return -1\n",
    "    \n",
    "def process_data(df):\n",
    "    df = df.drop(['Unnamed: 0', 'id'], axis = 1)\n",
    "    df['Gender'] = df['Gender'].apply(transform_gender)\n",
    "    df['Customer Type'] = df['Customer Type'].apply(transform_customer_type)\n",
    "    df['Type of Travel'] = df['Type of Travel'].apply(transform_travel_type)\n",
    "    df['Class'] = df['Class'].apply(transform_class)\n",
    "    df['satisfaction'] = df['satisfaction'].apply(transform_satisfaction)\n",
    "    df['Arrival Delay in Minutes'].fillna(df['Arrival Delay in Minutes'].median(), inplace = True)\n",
    "    \n",
    "    return df\n",
    "\n",
    "train = process_data(train)\n",
    "test = process_data(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! We now have every feature properly coded, almost time to start creating some models! But first, we will want to normalize our dataset via StandardScaler. Even if the model you are using does not care about a normalized dataset, I still like to do it just out of routine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define our features and target (this is helpful in case you would like to drop any features that harm model performance)\n",
    "features = ['Gender', 'Customer Type', 'Age', 'Type of Travel', 'Class',\n",
    "       'Flight Distance', 'Inflight wifi service',\n",
    "       'Departure/Arrival time convenient', 'Ease of Online booking',\n",
    "       'Gate location', 'Food and drink', 'Online boarding', 'Seat comfort',\n",
    "       'Inflight entertainment', 'On-board service', 'Leg room service',\n",
    "       'Baggage handling', 'Checkin service', 'Inflight service',\n",
    "       'Cleanliness', 'Departure Delay in Minutes', 'Arrival Delay in Minutes']\n",
    "target = ['satisfaction']\n",
    "\n",
    "# Split into test and train\n",
    "X_train = train[features]\n",
    "y_train = train[target].to_numpy()\n",
    "X_test = test[features]\n",
    "y_test = test[target].to_numpy()\n",
    "\n",
    "# Normalize Features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalization Complete! Also, just for kicks, lets take a look at a correlation heatmap to see which features correlate well with customer satisfaction.\n",
    "* **Best features** - Online Booking, Class, and Type of Travel\n",
    "* **Worst features** - Gate location, Gender, and Departure/Arrival Time Convenient\n",
    "\n",
    "We will keep all of our features in for now, but can always return to this step in case we want to drop features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [],
   "source": [
    "corr = train.corr(method='spearman')\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.zeros_like(corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(20, 18))\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(corr, annot = True, mask=mask, cmap=\"YlGnBu\", center=0,\n",
    "            square=True, linewidths=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "Now to the models! We will be trying out a few different models to see which one is the best choice for our problem. I have created a small function below which will train, predict, and evaluate all of our models. We will be evaluating performance of our models with the ROC_AUC metric. This metric is good for classification of a dataset which a relatively balance dataset in terms of our target. We will also be looking at the confusion matrix for our model to best understand how our model is mischaracterizing predictions (Are we seeing majority false positives? etc.) \n",
    "\n",
    "Note that I did some hyperparameter tuning on some of the models, but not all. I will be publishing another kernel showing how to tune hyperparameters, so stay tuned!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_model(model, X_train, y_train, X_test, y_test, verbose=True):\n",
    "    if verbose == False:\n",
    "        model.fit(X_train,y_train, verbose=0)\n",
    "    else:\n",
    "        model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    print(\"ROC_AUC = {}\".format(roc_auc))\n",
    "    print(classification_report(y_test,y_pred,digits=5))\n",
    "    plot_confusion_matrix(model, X_test, y_test,cmap=plt.cm.Blues, normalize = 'all')\n",
    "    \n",
    "    return model, roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest \n",
    "\n",
    "A great place to start! We are seeing an accuracy of 96.30%. Lets see if the other models can compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_rf = {'max_depth': 25,\n",
    "         'min_samples_leaf': 1,\n",
    "         'min_samples_split': 2,\n",
    "         'n_estimators': 1200,\n",
    "         'random_state': 42}\n",
    "\n",
    "model_rf = RandomForestClassifier(**params_rf)\n",
    "model_rf, roc_auc_rf = run_model(model_rf, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LightGBM\n",
    "\n",
    "Not bad LightGBM! But not quite up at 'Random Forest' levels. Lets keep going!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_lgb ={'colsample_bytree': 0.85, \n",
    "         'max_depth': 15, \n",
    "         'min_split_gain': 0.1, \n",
    "         'n_estimators': 200, \n",
    "         'num_leaves': 50, \n",
    "         'reg_alpha': 1.2, \n",
    "         'reg_lambda': 1.2, \n",
    "         'subsample': 0.95, \n",
    "         'subsample_freq': 20}\n",
    "\n",
    "model_lgb = lgb.LGBMClassifier(**params_lgb)\n",
    "model_lgb, roc_auc_lgb = run_model(model_lgb, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Catboost\n",
    "\n",
    "Pretty good for not having tuned hyperparameters here. Expect a performance boost once that is completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_cb ={}\n",
    "\n",
    "model_cb = cb.CatBoostClassifier(**params_cb)\n",
    "model_cb, roc_auc_cb = run_model(model_cb, X_train, y_train, X_test, y_test, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost\n",
    "\n",
    "I expected more from you XGBoost ;)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_xgb ={}\n",
    "\n",
    "model_xgb = xgb.XGBClassifier(**params_xgb)\n",
    "model_xgb, roc_auc_xgb = run_model(model_xgb, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparison and Conclusions\n",
    "\n",
    "Based on the roc_auc metric, we have a clean winner. Our Random forest classifier outperformed all of our other models. One thing to keep in mind is that both the Catboost and the XGBoost classifiers just used default parameters without any hyperparameter tuning. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_kg_hide-input": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>0.960729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LightGBM</th>\n",
       "      <td>0.962653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Catboost</th>\n",
       "      <td>0.961873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGBoost</th>\n",
       "      <td>0.938496</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    AUC\n",
       "Random Forest  0.960729\n",
       "LightGBM       0.962653\n",
       "Catboost       0.961873\n",
       "XGBoost        0.938496"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc_scores = [roc_auc_rf, roc_auc_lgb, roc_auc_cb, roc_auc_xgb]\n",
    "model_scores = pd.DataFrame(auc_scores, index=['Random Forest','LightGBM','Catboost','XGBoost'], columns=['AUC'])\n",
    "model_scores.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
